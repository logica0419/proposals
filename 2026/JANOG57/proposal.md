# 今こそ学びたいKubernetesネットワーク ～CNIが繋ぐNWとプラットフォームの「フラッと」な対話

## Status

### ❔ In Evaluation

## 発表概要

Kubernetesのネットワークが何もわからないから、Kubernetes基盤を運用するプラットフォームエンジニアとどう関わればいいかわからない...  
皆さん、こんな悩みを抱えてはいませんか？

近年のクラウド基盤の発展に伴い、オンプレミス環境においてもKubernetesなどクラウドネイティブな基盤の需要が高まり続けています。  
CNI(Container Network Interface)は、そのKubernetesにおいてコンテナ間通信を担う中核コンポーネントです。

CNIは「コンテナを何かしらのネットワークに接続する」ための仕組みであり、どんなネットワーク技術であってもフラットにコンテナネットワークと繋ぐ、NWとプラットフォームの窓口として設計されています。  
しかし「Kubernetesは難しい」という偏見のせいもあり、CNIはネットワークエンジニアとプラットフォームエンジニアの双方にとってブラックボックス化し、時にフラットな対話を阻む壁となることがあります。  
本発表は、このCNIを思想と実装の両面からフラットな目線で紐解き、CNIを通してネットワークとプラットフォームが手を取り合うためのヒントを見つける場です。

そもそも「CNI」という言葉は、CNIの仕様(本体)、基盤(Kubernetesなど)が求める要件、それらの実装であるCNIプラグインの3つをまとめて指すことが多い用語です。  
本発表では、CNIの仕様が示す「どんなネットワーク技術もフラットに受け入れる」という柔軟な設計思想を紐解き、Kubernetesなどの基盤がどのような要件を定義しているか整理します。  
その上で、Flannel・Calico・Ciliumといった主要CNIプラグインの実装を比較し、それらがどのようにオーバーレイ(VXLANやVPN)、L3ルーティング(BGP)、eBPFといった異なるアプローチでコンテナネットワークを構築しているのかを解説します。

オンプレコンテナ環境を運用している現場では、プラットフォームチームがメジャーなCNIプラグインを選定し、ネットワークチームはそこにノータッチという状況も少なくありません。  
しかし、メジャーなCNIプラグインは「どんな環境でも動く」汎用性を持つ一方で、その裏には見過ごされがちなオーバーヘッドや設計上のトレードオフが存在します。  
SR-IOVなどのシンプルな仕組みでコンテナを疎通させられる環境においても、VXLANを使ったオーバーレイネットワークを使っているような例は多々あります。  
このようなオーバーヘッドの多い非効率なネットワークを作らないために、ネットワークとプラットフォームのフラットな対話は必要不可欠なのです。

CNIを思想と実装に分けて理解することで、自分たちの環境に合わせたCNIの選定・チューニング・カスタマイズ、さらには自作も視野に入れた最適化の方向性を考えることができるでしょう。  
CNIをブラックボックスからユビキタス言語へ。ネットワークとプラットフォームが「フラッと」に対話できる基盤設計を、ここから一緒に考えてみましょう。

## 議論のポイント

1. CNI選定の基準は何か？
   - プラットフォーム視点とネットワーク視点で、どのように選定基準が異なるか
   - ネットワークエンジニアはどのようにプラットフォームに助言できるのか
2. ネットワークとプラットフォームの責任分界点
   - CNIを誰がどこまで理解し、管理するべきか？
   - CNIを「どちらも触らない」ではなく「どちらも触る」にするために、双方は何ができるか
3. どんな環境でも動く汎用設計と現場最適化のバランス
   - メジャーなプラグインが提供する汎用実装のオーバーヘッドは、どこまで許容できるか
   - EKSやAKEがやっているような自社仮想ネットワークへの最適化は、現実的な選択肢になり得るか
   - CNIプラグイン自作・改変は現実的な選択肢か。現場で取り得る「最適化レベル」はどこか
4. 次世代のCNIやコンテナネットワークの未来は？
   - eBPFベースの高速化、SRv6統合、クラウド横断ネットワークなど、次世代の方向性はどうなるか
   - DraNetなどのAIワークロードに対する最適化は、この先どのように進めるべきか

## 希望発表時間

60分（うち議論時間20分以上）

## 上記時間のうち、想定する議論時間

25分

## プログラム形式

単独発表
